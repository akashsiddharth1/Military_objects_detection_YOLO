{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1pLVgV75BLHKVCC-ZyqetKugsjlahbQ4B",
      "authorship_tag": "ABX9TyN+9gMaZ9+6JMWuXTSzzuKV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashsiddharth1/Military_objects_detection_YOLO/blob/main/militaryobject_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weapon Detection Using YOLO and Computer Vision\n",
        "This notebook provides a complete code workflow—with clear comments and explanations—for weapon detection using the latest YOLO model, covering data analysis, model training, real-time deployment, and a Streamlit web app."
      ],
      "metadata": {
        "id": "zX-9BgqPUyzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "SPEeLOJLG5HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP4mlzGYpf2G",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "E5HGJ1-mVWMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow albumentations"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XOwZUNp5VZiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "import json\n",
        "from PIL import Image, ImageEnhance, ImageStat,  UnidentifiedImageError\n",
        "import yaml\n",
        "from collections import defaultdict, Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "9tycuFHPVpBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.io import imread\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk\n",
        "from skimage.color import rgb2gra\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "WyUccr89s3vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import tempfile\n",
        "import streamlit as st"
      ],
      "metadata": {
        "id": "UP9xrVYpVv2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection and Preparation\n",
        "**a. Directory Structure**"
      ],
      "metadata": {
        "id": "VF2RhlC4jXJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base dataset directory\n",
        "dataset_path = Path('/content/drive/MyDrive/Files/military_object_dataset')\n",
        "\n",
        "# Paths for each subset\n",
        "train_images = dataset_path / 'train' / 'images'\n",
        "train_labels = dataset_path / 'train' / 'labels'\n",
        "\n",
        "val_images = dataset_path / 'val' / 'images'\n",
        "val_labels = dataset_path / 'val' / 'labels'\n",
        "\n",
        "test_images = dataset_path / 'test' / 'images'\n",
        "test_labels = dataset_path / 'test' / 'labels'"
      ],
      "metadata": {
        "id": "uuOlUEb4WAtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset integrity: images and labels count\n",
        "\n",
        "def count_images_labels(base_path):\n",
        "    subsets = ['train', 'val', 'test']\n",
        "    for subset in subsets:\n",
        "        images_dir = base_path / subset / 'images'\n",
        "        labels_dir = base_path / subset / 'labels'\n",
        "\n",
        "        image_files = [f for f in images_dir.iterdir() if f.suffix in ['.jpg', '.png']]\n",
        "        label_files = [f for f in labels_dir.iterdir() if f.suffix == '.txt']\n",
        "\n",
        "        print(f'--- {subset.upper()} ---')\n",
        "        print(f'Images Count: {len(image_files)}')\n",
        "        print(f'Labels Count: {len(label_files)}')\n",
        "\n",
        "# Example Usage:\n",
        "dataset_path = Path('/content/drive/MyDrive/Files/military_object_dataset')\n",
        "count_images_labels(dataset_path)\n"
      ],
      "metadata": {
        "id": "8_4v4GMRc1Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to verify each image has a corresponding label file\n",
        "\n",
        "def verify_images_have_labels(base_path):\n",
        "    subsets = ['train', 'val', 'test']\n",
        "    for subset in subsets:\n",
        "        images_dir = base_path / subset / 'images'\n",
        "        labels_dir = base_path / subset / 'labels'\n",
        "\n",
        "        # Collect image and label filenames (without extension)\n",
        "        image_stems = {f.stem for f in images_dir.iterdir() if f.suffix in ['.jpg', '.png']}\n",
        "        label_stems = {f.stem for f in labels_dir.iterdir() if f.suffix == '.txt'}\n",
        "\n",
        "        # Identify images without corresponding labels\n",
        "        missing_labels = image_stems - label_stems\n",
        "\n",
        "        print(f'\\n--- {subset.upper()} ---')\n",
        "        if missing_labels:\n",
        "            print(f'Images missing labels: {missing_labels}')\n",
        "        else:\n",
        "            print('✅ All images have corresponding label files.')\n",
        "\n",
        "# Example usage:\n",
        "dataset_path = Path('/content/drive/MyDrive/Files/military_object_dataset')\n",
        "verify_images_have_labels(dataset_path)\n"
      ],
      "metadata": {
        "id": "FD6-9sKMgcwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resize Images to Uniform Size"
      ],
      "metadata": {
        "id": "RypV0jHFmJP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "subsets = ['train', 'val', 'test']\n",
        "target_size = (640, 640)\n",
        "\n",
        "for subset in subsets:\n",
        "        images_dir = dataset_path / subset / 'images'\n",
        "        for img_file in images_dir.iterdir():\n",
        "            if img_file.suffix in ['.jpg', '.jpeg' '.png']:\n",
        "                try:\n",
        "                    img = Image.open(img_file)\n",
        "                    img = img.resize(target_size)\n",
        "                    # Convert to RGB before saving as JPEG to handle potential RGBA images\n",
        "                    if img.mode == 'RGBA':\n",
        "                        img = img.convert('RGB')\n",
        "                    img.save(img_file)\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not process image {img_file}: {e}\")"
      ],
      "metadata": {
        "id": "rIj-4eKosM_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Find corrupt files(images)**"
      ],
      "metadata": {
        "id": "zqwG0w0H4Bde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_corrupt_images(base_path):\n",
        "    subsets = ['train', 'val', 'test']\n",
        "    for subset in subsets:\n",
        "        images_dir = base_path / subset / 'images'\n",
        "        for img_file in images_dir.iterdir():\n",
        "            if img_file.suffix in ['.jpg', '.png']:\n",
        "                try:\n",
        "                    img = Image.open(img_file)\n",
        "                    img.verify()\n",
        "                except (UnidentifiedImageError, OSError):\n",
        "                    print(f\"Corrupted image: {img_file}\")\n",
        "\n",
        "# Usage\n",
        "find_corrupt_images(Path('/content/drive/MyDrive/Files/military_object_dataset'))\n"
      ],
      "metadata": {
        "id": "bOrufdrC4jT4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA\n",
        "Image Analysis"
      ],
      "metadata": {
        "id": "3fYfGjsbnEhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to collect image info\n",
        "\n",
        "def analyze_images(base_path):\n",
        "    image_info = []\n",
        "\n",
        "    subsets = ['train', 'val', 'test']\n",
        "    for subset in subsets:\n",
        "        images_dir = base_path / subset / 'images'\n",
        "        for img_file in images_dir.iterdir():\n",
        "            if img_file.suffix in ['.jpg', '.png']:\n",
        "                try:\n",
        "                    img = Image.open(img_file)\n",
        "                    width, height = img.size\n",
        "                    aspect_ratio = width / height\n",
        "                    stat = ImageStat.Stat(img.convert('L'))\n",
        "                    brightness = stat.mean[0]\n",
        "                    image_info.append({\n",
        "                        'subset': subset,\n",
        "                        'filename': img_file.name,\n",
        "                        'width': width,\n",
        "                        'height': height,\n",
        "                        'aspect_ratio': aspect_ratio,\n",
        "                        'brightness': brightness\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_file}: {e}\")\n",
        "\n",
        "    return image_info\n",
        "\n",
        "\n",
        "# Usage\n",
        "dataset_path = Path('/content/drive/MyDrive/Files/military_object_dataset')\n",
        "image_data = analyze_images(dataset_path)"
      ],
      "metadata": {
        "id": "90QZQ3ErnERJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Size and Resolution Distribution"
      ],
      "metadata": {
        "id": "lTo88K1BmzQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(df['width'], bins=20, color='skyblue')\n",
        "plt.title('Image Width Distribution')\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(df['height'], bins=20, color='salmon')\n",
        "plt.title('Image Height Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NkVQIgITtYRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aspect Ratio Distribution"
      ],
      "metadata": {
        "id": "gQJ6dS_uudCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df['aspect_ratio'], bins=20, color='green')\n",
        "plt.title('Image Aspect Ratio Distribution (W/H)')\n",
        "plt.xlabel('Aspect Ratio')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_xWWMvasulnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Blurry Images"
      ],
      "metadata": {
        "id": "RRLARkiPwB2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_blurry_images(base_dir, threshold=100.0):\n",
        "    blurry_images = []\n",
        "\n",
        "    subsets = ['train', 'val', 'test']\n",
        "    for subset in subsets:\n",
        "        images_dir = base_dir / subset / 'images'\n",
        "        for img_file in images_dir.iterdir():\n",
        "            if img_file.suffix in ['.jpg', '.png']:\n",
        "                img = cv2.imread(str(img_file), cv2.IMREAD_GRAYSCALE)\n",
        "                if img is not None:\n",
        "                    variance = cv2.Laplacian(img, cv2.CV_64F).var()\n",
        "                    if variance < threshold:\n",
        "                        blurry_images.append({\n",
        "                            'subset': subset,\n",
        "                            'filename': img_file.name,\n",
        "                            'blurriness': variance\n",
        "                        })\n",
        "\n",
        "    return blurry_images\n",
        "\n",
        "\n",
        "# Usage\n",
        "dataset_path = Path('/content/drive/MyDrive/Files/military_object_dataset')\n",
        "blurry_images = detect_blurry_images(dataset_path)\n",
        "print(\"\\nPotential Blurry Images:\")\n",
        "for item in blurry_images:\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "HMRrI3QBmtM9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Underexposed / Overexposed Images"
      ],
      "metadata": {
        "id": "ZIHp2jK4nyB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_exposure_issues(base_dir, dark_threshold=30, bright_threshold=220):\n",
        "    underexposed = []\n",
        "    overexposed = []\n",
        "\n",
        "    subsets = ['train', 'val', 'test']\n",
        "    for subset in subsets:\n",
        "        images_dir = base_dir / subset / 'images'\n",
        "        for img_file in images_dir.iterdir():\n",
        "            if img_file.suffix in ['.jpg', '.png']:\n",
        "                img = Image.open(img_file).convert('L')  # Grayscale\n",
        "                stat = ImageStat.Stat(img)\n",
        "                brightness = stat.mean[0]\n",
        "\n",
        "                if brightness < dark_threshold:\n",
        "                    underexposed.append((subset, img_file.name, brightness))\n",
        "                elif brightness > bright_threshold:\n",
        "                    overexposed.append((subset, img_file.name, brightness))\n",
        "\n",
        "    return underexposed, overexposed\n",
        "\n",
        "\n",
        "underexposed, overexposed = detect_exposure_issues(dataset_path)\n",
        "\n",
        "print(\"\\nUnderexposed Images:\")\n",
        "for item in underexposed:\n",
        "    print(item)\n",
        "\n",
        "print(\"\\nOverexposed Images:\")\n",
        "for item in overexposed:\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "Zzu2M_zcm8j2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Noise"
      ],
      "metadata": {
        "id": "MW2vf6qfn3_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_noisy_images(base_dir, entropy_threshold=7.0):\n",
        "    noisy_images = []\n",
        "\n",
        "    subsets = ['train', 'val', 'test']\n",
        "    for subset in subsets:\n",
        "        images_dir = base_dir / subset / 'images'\n",
        "        for img_file in images_dir.iterdir():\n",
        "            if img_file.suffix in ['.jpg', '.png']:\n",
        "                img = imread(str(img_file))\n",
        "                if img.ndim == 3:\n",
        "                    # Check if the image has an alpha channel (4 channels)\n",
        "                    if img.shape[-1] == 4:\n",
        "                        img = img[..., :3]  # Remove alpha channel\n",
        "                    img = rgb2gray(img)\n",
        "                img = (img * 255).astype(np.uint8)\n",
        "                entropy_img = entropy(img, disk(5))\n",
        "                mean_entropy = entropy_img.mean()\n",
        "\n",
        "                if mean_entropy > entropy_threshold:\n",
        "                    noisy_images.append({\n",
        "                        'subset': subset,\n",
        "                        'filename': img_file.name,\n",
        "                        'entropy': mean_entropy\n",
        "                    })\n",
        "\n",
        "    return noisy_images\n",
        "\n",
        "\n",
        "noisy_images = detect_noisy_images(dataset_path)\n",
        "print(\"\\nPotential Noisy Images (High Entropy):\")\n",
        "for item in noisy_images:\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "7Tm42GoanFFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Size, Aspect Ratio, Quality (EDA)"
      ],
      "metadata": {
        "id": "9_1DqpKP8Miu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Annotation Analysis:\n",
        "a. Number of Annotations per Image"
      ],
      "metadata": {
        "id": "pID0-cr0o0DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records = []\n",
        "\n",
        "for subset in subsets:\n",
        "    labels_dir = dataset_path / subset / 'labels'\n",
        "    images_dir = dataset_path / subset / 'images'\n",
        "\n",
        "    for label_file in labels_dir.glob('*.txt'):\n",
        "        img_file = images_dir / (label_file.stem + '.jpg')\n",
        "        if not img_file.exists():\n",
        "            img_file = images_dir / (label_file.stem + '.png')\n",
        "        if not img_file.exists():\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_file)\n",
        "            img_width, img_height = img.size\n",
        "        except UnidentifiedImageError:\n",
        "            print(f\"Skipping corrupted image: {img_file}\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                try:\n",
        "                    # Safely attempt float conversion\n",
        "                    class_id, cx, cy, w, h = map(float, parts[:5])\n",
        "                except ValueError:\n",
        "                    print(f\"Skipping invalid label line in {label_file}: {line.strip()}\")\n",
        "                    continue\n",
        "\n",
        "                box_width = w * img_width\n",
        "                box_height = h * img_height\n",
        "                aspect_ratio = box_width / box_height if box_height != 0 else 0\n",
        "\n",
        "                records.append({\n",
        "                    'subset': subset,\n",
        "                    'filename': label_file.stem,\n",
        "                    'class_id': class_id,\n",
        "                    'box_width': box_width,\n",
        "                    'box_height': box_height,\n",
        "                    'aspect_ratio': aspect_ratio\n",
        "                })\n",
        "\n",
        "df_annotations = pd.DataFrame(records)\n",
        "df_annotations.head()\n"
      ],
      "metadata": {
        "id": "2jE-4iJbo6Tl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class Frequency & Co-occurrence\n",
        "\n",
        "sns.countplot(data=df_annotations, x='class_id', hue='subset')\n",
        "plt.title('Class Distribution per Split')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "km8GYwwttmYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bounding box size distribution\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.histplot(df_annotations['box_width'], color='blue', label='Width', kde=True)\n",
        "sns.histplot(df_annotations['box_height'], color='orange', label='Height', kde=True\n",
        "plt.legend()\n",
        "plt.title('Bounding Box Width & Height Distribution (Pixels)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cv9OzstetpbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Percentage size relative to standard YOLO image size (assuming 640x640)\n",
        "df_annotations['area_percent'] = (df_annotations['box_width'] * df_annotations['box_height']) / (640*640) * 100\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df_annotations['area_percent'], kde=True)\n",
        "plt.title('Bounding Box Area as % of Image (640x640)')\n",
        "plt.xlabel('Bounding Box Area % of Image')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N0pVely0tvr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bounding box aspect ratio\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df_annotations['aspect_ratio'], kde=True)\n",
        "plt.title('Bounding Box Aspect Ratio Distribution (Width / Height)')\n",
        "plt.xlabel('Aspect Ratio')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_FJyh2xKtwpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Distribution analysis"
      ],
      "metadata": {
        "id": "T-MiMW_M_9Q3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class frequency"
      ],
      "metadata": {
        "id": "2VJltrERBEPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset path\n",
        "dataset_path = Path('./dataset')\n",
        "subsets = ['train', 'val', 'test']\n",
        "\n",
        "# Count class IDs from label files\n",
        "class_counts = Counter()\n",
        "\n",
        "for subset in subsets:\n",
        "    labels_dir = dataset_path / subset / 'labels'\n",
        "    label_files = list(labels_dir.glob('*.txt'))\n",
        "\n",
        "    for label_file in label_files:\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    try:\n",
        "                        class_id = int(float(parts[0]))  # Ensure it's an int\n",
        "                        class_counts[class_id] += 1\n",
        "                    except ValueError:\n",
        "                        print(f\"Skipping invalid line in {label_file}: {line.strip()}\")\n",
        "                        continue\n",
        "\n",
        "# Class names as per your mapping\n",
        "class_names = {\n",
        "    0: 'camouflage_soldier',\n",
        "    1: 'weapon',\n",
        "    2: 'military_tank',\n",
        "    3: 'military_truck',\n",
        "    4: 'military_vehicle',\n",
        "    5: 'civilian',\n",
        "    6: 'soldier',\n",
        "    7: 'civilian_vehicle',\n",
        "    8: 'trench'\n",
        "}\n",
        "\n",
        "# Convert to DataFrame for visualization\n",
        "class_data = pd.DataFrame([\n",
        "    {'class_id': class_id, 'class_name': class_names[class_id], 'count': count}\n",
        "    for class_id, count in sorted(class_counts.items())\n",
        "])\n",
        "\n",
        "print(class_data)\n",
        "\n",
        "# Plotting (Optional)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_data['class_name'], class_data['count'], color='skyblue')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Number of Annotations')\n",
        "plt.title('Class Distribution in Dataset')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C9wDvT12BH5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CO - occurrence"
      ],
      "metadata": {
        "id": "7W3Sd3jhtJGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "dataset_path = Path('./dataset')\n",
        "subsets = ['train', 'val', 'test']\n",
        "\n",
        "# Initialize dictionary to store sets of classes per image\n",
        "image_classes = defaultdict(set)\n",
        "\n",
        "for subset in subsets:\n",
        "    labels_dir = dataset_path / subset / 'labels'\n",
        "    label_files = list(labels_dir.glob('*.txt'))\n",
        "\n",
        "    for label_file in label_files:\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    try:\n",
        "                        class_id = int(float(parts[0]))\n",
        "                        image_classes[label_file.name].add(class_id)\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "\n",
        "# Build co-occurrence matrix\n",
        "num_classes = 9\n",
        "co_occurrence = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "for classes_in_img in image_classes.values():\n",
        "    classes_in_img = list(classes_in_img)\n",
        "    for i in range(len(classes_in_img)):\n",
        "        for j in range(len(classes_in_img)):\n",
        "            co_occurrence[classes_in_img[i], classes_in_img[j]] += 1\n",
        "\n",
        "# Class names as per your mapping\n",
        "class_names = [\n",
        "    'camouflage_soldier', 'weapon', 'military_tank', 'military_truck',\n",
        "    'military_vehicle', 'civilian', 'soldier', 'civilian_vehicle', 'trench'\n",
        "]\n",
        "\n",
        "# Convert to DataFrame for heatmap\n",
        "df_co_occurrence = pd.DataFrame(co_occurrence, index=class_names, columns=class_names)\n",
        "\n",
        "# 🔥 Plotting heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df_co_occurrence, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Class Co-occurrence Heatmap')\n",
        "plt.ylabel('Class')\n",
        "plt.xlabel('Class')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "i6SI4HnctMwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization**"
      ],
      "metadata": {
        "id": "dP1R9PDaEFPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Class names (as per your dataset)\n",
        "class_names = [\n",
        "    'camouflage_soldier', 'weapon', 'military_tank', 'military_truck',\n",
        "    'military_vehicle', 'civilian', 'soldier', 'civilian_vehicle', 'trench'\n",
        "]\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = Path('./dataset')\n",
        "subset = 'train'  # Change to 'val' or 'test' if needed\n",
        "\n",
        "images_dir = dataset_path / subset / 'images'\n",
        "labels_dir = dataset_path / subset / 'labels'\n",
        "\n",
        "# Pick random sample images\n",
        "img_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
        "sample_files = random.sample(img_files, min(5, len(img_files)))  # Visualize 5 samples\n",
        "\n",
        "# Plot images with annotations\n",
        "for img_file in sample_files:\n",
        "    img = cv2.imread(str(img_file))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    label_file = labels_dir / (img_file.stem + '.txt')\n",
        "    if label_file.exists():\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                class_id, cx, cy, bw, bh = map(float, line.split())\n",
        "                x_center, y_center = cx * w, cy * h\n",
        "                box_w, box_h = bw * w, bh * h\n",
        "                x1 = int(x_center - box_w / 2)\n",
        "                y1 = int(y_center - box_h / 2)\n",
        "                x2 = int(x_center + box_w / 2)\n",
        "                y2 = int(y_center + box_h / 2)\n",
        "\n",
        "                class_name = class_names[int(class_id)]\n",
        "                color = (255, 0, 0)\n",
        "\n",
        "                cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(img, class_name, (x1, max(y1 - 10, 0)),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'{subset.upper()}: {img_file.name}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "F29uyk-nEMdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heatmap"
      ],
      "metadata": {
        "id": "MY3wpn0jqU3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset path and subset\n",
        "dataset_path = Path('./dataset')\n",
        "subsets = ['train', 'val', 'test']\n",
        "\n",
        "# Heatmap canvas size (match image size if fixed, else average like 640x640)\n",
        "canvas_w, canvas_h = 640, 640\n",
        "heatmap = np.zeros((canvas_h, canvas_w))\n",
        "\n",
        "# Collect bounding box centers across all subsets\n",
        "for subset in subsets:\n",
        "    images_dir = dataset_path / subset / 'images'\n",
        "    labels_dir = dataset_path / subset / 'labels'\n",
        "    img_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
        "\n",
        "    for img_file in tqdm(img_files, desc=f'Processing {subset}'):\n",
        "        img = cv2.imread(str(img_file))\n",
        "        if img is None:\n",
        "            continue\n",
        "        h, w = img.shape[:2]\n",
        "        label_file = labels_dir / (img_file.stem + '.txt')\n",
        "        if label_file.exists():\n",
        "            with open(label_file, 'r') as f:\n",
        "                for line in f.readlines():\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) >= 5:\n",
        "                        class_id, cx, cy, bw, bh = map(float, parts[:5])\n",
        "                        x_center = int(cx * canvas_w)\n",
        "                        y_center = int(cy * canvas_h)\n",
        "                        # Increase heatmap density at this point\n",
        "                        if 0 <= x_center < canvas_w and 0 <= y_center < canvas_h:\n",
        "                            heatmap[y_center, x_center] += 1\n",
        "\n",
        "# Apply Gaussian blur for smoother heatmap visualization\n",
        "heatmap = cv2.GaussianBlur(heatmap, (0, 0), sigmaX=10, sigmaY=10)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(heatmap, cmap='hot', interpolation='nearest')\n",
        "plt.title('Object Density Heatmap Across Dataset')\n",
        "plt.colorbar(label='Density of Objects')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CzMFKtVcHSEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bounding Box Size / Area Per Class\n"
      ],
      "metadata": {
        "id": "2KBzCTa7qaUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset path and subsets\n",
        "dataset_path = Path('./dataset')\n",
        "subsets = ['train', 'val', 'test']\n",
        "\n",
        "# Store records of bounding box widths and heights (in pixels)\n",
        "records = []\n",
        "\n",
        "for subset in subsets:\n",
        "    labels_dir = dataset_path / subset / 'labels'\n",
        "    images_dir = dataset_path / subset / 'images'\n",
        "\n",
        "    for label_file in labels_dir.glob('*.txt'):\n",
        "        img_file = images_dir / (label_file.stem + '.jpg')\n",
        "        if not img_file.exists():\n",
        "            img_file = images_dir / (label_file.stem + '.png')\n",
        "        if not img_file.exists():\n",
        "            continue\n",
        "        img = cv2.imread(str(img_file))\n",
        "        if img is None:\n",
        "            continue\n",
        "        img_h, img_w = img.shape[:2]\n",
        "\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                class_id, cx, cy, bw, bh = map(float, parts[:5])\n",
        "                width_pixels = bw * img_w\n",
        "                height_pixels = bh * img_h\n",
        "                area_pixels = width_pixels * height_pixels\n",
        "                records.append({\n",
        "                    'subset': subset,\n",
        "                    'class_id': int(class_id),\n",
        "                    'width': width_pixels,\n",
        "                    'height': height_pixels,\n",
        "                    'area': area_pixels\n",
        "                })\n",
        "\n",
        "df_boxes = pd.DataFrame(records)\n"
      ],
      "metadata": {
        "id": "yU92NHBuuV3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Boxplots of Bounding Box Areas Per Class"
      ],
      "metadata": {
        "id": "7psdCNpUubz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\n",
        "    'camouflage_soldier', 'weapon', 'military_tank', 'military_truck',\n",
        "    'military_vehicle', 'civilian', 'soldier', 'civilian_vehicle', 'trench'\n",
        "]\n",
        "df_boxes['class_name'] = df_boxes['class_id'].apply(lambda x: class_names[x])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "df_boxes.boxplot(column='area', by='class_name', grid=False, rot=45)\n",
        "plt.title('Bounding Box Area Distribution per Class')\n",
        "plt.ylabel('Area (pixels)')\n",
        "plt.xlabel('Class Name')\n",
        "plt.suptitle('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F5Rb1MAguZRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Histograms of Widths & Heights Per Class"
      ],
      "metadata": {
        "id": "BBlDPF2jun26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df_boxes, x='width', hue='class_name', bins=50, element='step', stat='density')\n",
        "plt.title('Bounding Box Width Distribution by Class')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df_boxes, x='height', hue='class_name', bins=50, element='step', stat='density')\n",
        "plt.title('Bounding Box Height Distribution by Class')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vZo-fEZfunny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATASET SPLITS**"
      ],
      "metadata": {
        "id": "sycyu3_9S_KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset_path = Path('/content/drive/MyDrive/Files/military_object_dataset')\n",
        "subsets = ['train', 'val', 'test']\n",
        "\n",
        "split_data = []\n",
        "\n",
        "for subset in subsets:\n",
        "    images_dir = dataset_path / subset / 'images'\n",
        "    labels_dir = dataset_path / subset / 'labels'\n",
        "\n",
        "    images = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
        "    labels = list(labels_dir.glob('*.txt'))\n",
        "\n",
        "    annotation_count = 0\n",
        "    class_ids = []\n",
        "\n",
        "    for label_file in labels:\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        annotation_count += len(lines)\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 1:\n",
        "                class_ids.append(int(parts[0]))\n",
        "\n",
        "    split_data.append({\n",
        "        'Subset': subset,\n",
        "        'Images': len(images),\n",
        "        'Annotations': annotation_count,\n",
        "        'Unique Classes': sorted(set(class_ids)),\n",
        "        'Total Unique Classes': len(set(class_ids))\n",
        "    })\n",
        "\n",
        "df_splits = pd.DataFrame(split_data)\n",
        "df_splits"
      ],
      "metadata": {
        "id": "6qmv4lCZTBTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visulaize split data\n",
        "sns.barplot(data=df_splits, x='Subset', y='Images')\n",
        "plt.title('Number of Images in Each Split')\n",
        "plt.show()\n",
        "\n",
        "sns.barplot(data=df_splits, x='Subset', y='Annotations')\n",
        "plt.title('Number of Annotations in Each Split')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "63Y6yXR9TLiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Class Distribution Across Splits"
      ],
      "metadata": {
        "id": "Fgp9x3lM6q5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df_annotations, x='class_id', hue='subset')\n",
        "plt.title('Class Distribution per Split')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kj1wvvV04X7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Data Leakage (Same Images in Multiple Splits)"
      ],
      "metadata": {
        "id": "2Hzla_7yIUE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_files = {subset: set() for subset in subsets}\n",
        "\n",
        "for subset in subsets:\n",
        "    images_dir = dataset_path / subset / 'images'\n",
        "    img_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
        "    subset_files[subset] = {img_file.stem for img_file in img_files}\n",
        "\n",
        "train_val_overlap = subset_files['train'] & subset_files['val']\n",
        "train_test_overlap = subset_files['train'] & subset_files['test']\n",
        "val_test_overlap = subset_files['val'] & subset_files['test']\n",
        "\n",
        "print('Train-Val Overlap:', len(train_val_overlap), train_val_overlap)\n",
        "print('Train-Test Overlap:', len(train_test_overlap), train_test_overlap)\n",
        "print('Val-Test Overlap:', len(val_test_overlap), val_test_overlap)\n"
      ],
      "metadata": {
        "id": "6ofqyeD9ITbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation Analysis"
      ],
      "metadata": {
        "id": "TmB6H_NNu7VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Sample transform (safe for bounding boxes)\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),\n",
        "    A.MotionBlur(p=0.2),\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "# Sample image and labels\n",
        "dataset_path = Path('./dataset/train')\n",
        "images_dir = dataset_path / 'images'\n",
        "labels_dir = dataset_path / 'labels'\n",
        "\n",
        "img_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
        "img_file = random.choice(img_files)\n",
        "label_file = labels_dir / (img_file.stem + '.txt')\n",
        "\n",
        "img = cv2.imread(str(img_file))\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "h, w = img.shape[:2]\n",
        "\n",
        "# Load YOLO annotations\n",
        "bboxes = []\n",
        "labels = []\n",
        "with open(label_file, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        parts = list(map(float, line.strip().split()))\n",
        "        labels.append(int(parts[0]))\n",
        "        bboxes.append(parts[1:])\n",
        "\n",
        "# Apply augmentation\n",
        "augmented = transform(image=img, bboxes=bboxes, class_labels=labels)\n",
        "aug_img = augmented['image']\n",
        "aug_bboxes = augmented['bboxes']\n",
        "aug_labels = augmented['class_labels']\n",
        "\n",
        "# Visualize result\n",
        "def draw_boxes(image, bboxes, labels, color=(255, 0, 0)):\n",
        "    img_copy = image.copy()\n",
        "    for (cx, cy, bw, bh), cls in zip(bboxes, labels):\n",
        "        x1 = int((cx - bw / 2) * w)\n",
        "        y1 = int((cy - bh / 2) * h)\n",
        "        x2 = int((cx + bw / 2) * w)\n",
        "        y2 = int((cy + bh / 2) * h)\n",
        "        cv2.rectangle(img_copy, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(img_copy, f'{cls}', (x1, max(y1 - 10, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "    return img_copy\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "axes[0].imshow(draw_boxes(img, bboxes, labels))\n",
        "axes[0].set_title('Original')\n",
        "axes[1].imshow(draw_boxes(aug_img, aug_bboxes, aug_labels, color=(0, 255, 0)))\n",
        "axes[1].set_title('Augmented')\n",
        "for ax in axes: ax.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s_Q_o5s4u99S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenges and Insights\n",
        "Detecting small objects (like weapons) is a common challenge in object detection because:\n",
        "\n",
        "Small bounding boxes contain less information"
      ],
      "metadata": {
        "id": "6SxFykngvrsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_threshold = 0.02  # Define < 2% of image area as small\n",
        "\n",
        "# Assume images are roughly 640x640\n",
        "image_area = 640 * 640\n",
        "\n",
        "df_boxes['is_small'] = df_boxes['area'] / image_area < small_threshold\n",
        "\n",
        "# Count small vs. large objects per class\n",
        "small_objects_count = df_boxes.groupby(['class_name', 'is_small']).size().unstack(fill_value=0)\n",
        "\n",
        "# Plot percentage of small objects per class\n",
        "small_objects_percent = (small_objects_count[True] / (small_objects_count[True] + small_objects_count[False])) * 100\n",
        "small_objects_percent = small_objects_percent.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "small_objects_percent.plot(kind='bar', color='orange')\n",
        "plt.ylabel('% of Small Objects (<2% area)')\n",
        "plt.title('Percentage of Small Objects by Class')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EI4eIQW6vvSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Imbalance"
      ],
      "metadata": {
        "id": "u_EQoAwUwcXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=1.0),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.RandomScale(scale_limit=0.3, p=1.0),\n",
        "    A.Rotate(limit=15, p=0.7)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n"
      ],
      "metadata": {
        "id": "hQNlI2_2wbHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annotation Quality"
      ],
      "metadata": {
        "id": "TAZJlImiwe9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify images without label files\n",
        "missing_labels = []\n",
        "\n",
        "for subset in ['train', 'val', 'test']:\n",
        "    images_dir = dataset_path / subset / 'images'\n",
        "    labels_dir = dataset_path / subset / 'labels'\n",
        "    img_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
        "\n",
        "    for img_file in img_files:\n",
        "        label_file = labels_dir / (img_file.stem + '.txt')\n",
        "        if not label_file.exists():\n",
        "            missing_labels.append(img_file.name)\n",
        "\n",
        "print(f'Missing labels: {missing_labels}')\n"
      ],
      "metadata": {
        "id": "-ICYXWBIwiAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check each label line is in YOLO format\n",
        "errors = []\n",
        "\n",
        "for subset in ['train', 'val', 'test']:\n",
        "    labels_dir = dataset_path / subset / 'labels'\n",
        "    for label_file in labels_dir.glob('*.txt'):\n",
        "        with open(label_file, 'r') as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) != 5:\n",
        "                    errors.append(f'{label_file} line {idx+1}: Invalid format')\n",
        "\n",
        "if errors:\n",
        "    for e in errors: print(e)\n",
        "else:\n",
        "    print('All label files are properly formatted.')\n"
      ],
      "metadata": {
        "id": "n3piedvNwyoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN MODEL"
      ],
      "metadata": {
        "id": "UxdOOrEEJUnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_content = \"\"\"\n",
        "path: /content/drive/MyDrive/Files/military_object_dataset\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "nc: 9\n",
        "names: [camouflage_soldier, weapon, military_tank, military_truck, military_vehicle, civilian, soldier, civilian_vehicle, trench]\n",
        "\"\"\"\n",
        "\n",
        "with open('data.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n"
      ],
      "metadata": {
        "id": "lpD7JQL5Keov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "i5Q0TcTl-pMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.pt')  # You can use yolov8n.pt, yolov8s.pt, etc. (n=Nano, s=Small)\n",
        "\n",
        "model.train(\n",
        "    data='data.yaml',\n",
        "    epochs=5,\n",
        "    imgsz=416,\n",
        "    batch=16,\n",
        "    device='cuda'\n",
        ")"
      ],
      "metadata": {
        "id": "5q6_I5ClJWmo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REAL TIME OBJECT DETECTION\n",
        "Inference on Single Images"
      ],
      "metadata": {
        "id": "pPQF-eszzyRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your trained YOLOv8 model (best.pt after training)\n",
        "model = YOLO('/content/drive/MyDrive/Files/military_object_dataset/best.pt')\n",
        "\n",
        "# Inference on a single image\n",
        "results = model.predict(source='000003.jpg', save=True, conf=0.5)\n",
        "\n",
        "# Visualize the result in Colab\n",
        "# The results are saved to runs/detect/predictX where X is an incrementing number\n",
        "# We need to find the latest predict directory.\n",
        "import glob\n",
        "latest_predict_dir = max(glob.glob('runs/detect/predict*'), key=os.path.getctime)\n",
        "predicted_image_path = os.path.join(latest_predict_dir, '000003.jpg') # assuming the image name remains the same\n",
        "\n",
        "img = cv2.imread(predicted_image_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o0Aqdw6QzQG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference on a video file\n",
        "model.predict(source='your_video.mp4', save=True, conf=0.5)"
      ],
      "metadata": {
        "id": "gA1s-yUUz_B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classify Classes as Threat / Non-Threat"
      ],
      "metadata": {
        "id": "F4ao6kIHrFuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map class indices to names (YOLO class IDs)\n",
        "CLASS_NAMES = {\n",
        "    0: 'camouflage_soldier',\n",
        "    1: 'weapon',\n",
        "    2: 'military_tank',\n",
        "    3: 'military_truck',\n",
        "    4: 'military_vehicle',\n",
        "    5: 'civilian',\n",
        "    6: 'soldier',\n",
        "    7: 'civilian_vehicle',\n",
        "    8: 'trench',\n",
        "    9: 'person',\n",
        "    10: 'wheeled_vehicle',\n",
        "    11: 'tracked_vehicle'\n",
        "}\n",
        "\n",
        "# Define Threats and Non-Threats\n",
        "THREAT_CLASSES = {0, 1, 2, 3, 4, 9, 10, 11}      # IDs for threats\n",
        "NON_THREAT_CLASSES = {5, 6, 7, 8}     # IDs for non-threats\n",
        "\n",
        "def classify_threat(class_id):\n",
        "    if class_id in THREAT_CLASSES:\n",
        "        return 'Threat'\n",
        "    elif class_id in NON_THREAT_CLASSES:\n",
        "        return 'Non-Threat'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "model = YOLO('/content/drive/MyDrive/Files/military_object_dataset/best.pt')\n",
        "results = model.predict(source='/content/drive/MyDrive/Files/military_object_dataset/test/images/006010.jpg', conf=0.5, save=True)\n",
        "\n",
        "# Find the latest predict directory\n",
        "import glob\n",
        "latest_predict_dir = max(glob.glob('runs/detect/predict*'), key=os.path.getctime)\n",
        "predicted_image_path = os.path.join(latest_predict_dir, '006010.jpg')\n",
        "\n",
        "img = cv2.imread(predicted_image_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "for r in results:\n",
        "    for box in r.boxes:\n",
        "        class_id = int(box.cls[0])\n",
        "        label = CLASS_NAMES[class_id]\n",
        "        threat_status = classify_threat(class_id)\n",
        "        color = (255, 0, 0) if threat_status == 'Threat' else (0, 255, 0)\n",
        "\n",
        "        xyxy = box.xyxy[0].cpu().numpy().astype(int)\n",
        "        cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), color, 2)\n",
        "        cv2.putText(img, f\"{label} ({threat_status})\", (xyxy[0], xyxy[1] - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_-opuStRYzO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Evaluation:\n",
        "a. Evaluate the model's performance using metrics like precision, recall, and mean average precision (mAP).\n"
      ],
      "metadata": {
        "id": "CLa5nYhsrTrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your trained model\n",
        "model = YOLO('/kaggle/working/runs/detect/train2/weights/best.pt')\n",
        "\n",
        "# Evaluate on your validation or test set\n",
        "metrics = model.val()\n",
        "\n",
        "# This will automatically compute: Precision, Recall, mAP@0.5, mAP@0.5:0.95, etc."
      ],
      "metadata": {
        "id": "q6PQ51sjrVoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation\n",
        "metrics = results.box.map    # List of mAPs at different IoUs\n",
        "print(f'mAP@0.5: {metrics[0]:.3f}')\n",
        "print(f'mAP@0.5:0.95: {metrics[-1]:.3f}')\n",
        "print(f'Precision: {results.box.precision:.3f}')\n",
        "print(f'Recall: {results.box.recall:.3f}')\n",
        "print(f'Inference Time per Image (ms): {results.speed['inference']:.3f}')\n"
      ],
      "metadata": {
        "id": "vO-ASh5Sxhjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STREAMLIT APP"
      ],
      "metadata": {
        "id": "0tdkwe3hyE4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO model\n",
        "model = YOLO('best.pt')  # Replace with your trained YOLO model path\n",
        "\n",
        "# Helper to convert detection results to threat / non-threat\n",
        "def classify_threat(classes):\n",
        "    threat_classes = ['weapon', 'enemy_soldier', 'military_tank', 'military_truck']\n",
        "    if any(cls in classes for cls in threat_classes):\n",
        "        return 'Threat Detected'\n",
        "    else:\n",
        "        return 'Non-Threat'\n",
        "\n",
        "# Streamlit App UI\n",
        "st.title(\"Weapon & Threat Detection System\")\n",
        "st.sidebar.header(\"Upload Media\")\n",
        "\n",
        "upload_option = st.sidebar.radio(\"Choose Input Type\", [\"Image\", \"Video\"])\n",
        "\n",
        "if upload_option == \"Image\":\n",
        "    uploaded_file = st.sidebar.file_uploader(\"Upload an Image\", type=['jpg', 'jpeg', 'png'])\n",
        "\n",
        "    if uploaded_file:\n",
        "        img = Image.open(uploaded_file)\n",
        "        st.image(img, caption='Original Image', use_column_width=True)\n",
        "\n",
        "        img_array = np.array(img.convert('RGB'))\n",
        "\n",
        "        # YOLO Inference\n",
        "        results = model.predict(img_array, conf=0.3)\n",
        "        res_img = results[0].plot()\n",
        "\n",
        "        # Extract detected classes\n",
        "        detected_classes = [model.names[int(cls)] for cls in results[0].boxes.cls]\n",
        "\n",
        "        # Display\n",
        "        st.image(res_img, caption='Detection Result', use_column_width=True)\n",
        "        st.write(f\"**Classification:** {classify_threat(detected_classes)}\")\n",
        "        st.write(f\"**Detected Classes:** {detected_classes}\")\n",
        "\n",
        "        # Download button\n",
        "        res_pil = Image.fromarray(res_img)\n",
        "        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
        "        res_pil.save(tmp_file.name)\n",
        "        st.download_button(label=\"Download Annotated Image\", data=open(tmp_file.name, 'rb').read(), file_name='result.png', mime='image/png')\n",
        "\n",
        "if upload_option == \"Video\":\n",
        "    uploaded_video = st.sidebar.file_uploader(\"Upload a Video\", type=['mp4', 'mov', 'avi'])\n",
        "    if uploaded_video:\n",
        "        tfile = tempfile.NamedTemporaryFile(delete=False)\n",
        "        tfile.write(uploaded_video.read())\n",
        "        cap = cv2.VideoCapture(tfile.name)\n",
        "\n",
        "        stframe = st.empty()\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')\n",
        "        out = None\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            results = model.predict(frame, conf=0.3)\n",
        "            res_frame = results[0].plot()\n",
        "\n",
        "            if out is None:\n",
        "                h, w = res_frame.shape[:2]\n",
        "                out = cv2.VideoWriter(out_file.name, fourcc, 20.0, (w, h))\n",
        "\n",
        "            out.write(res_frame)\n",
        "            stframe.image(res_frame, channels=\"BGR\")\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        st.success(\"Video processing completed.\")\n",
        "        st.download_button(\"Download Processed Video\", open(out_file.name, 'rb').read(), file_name='result.mp4', mime='video/mp4')\n"
      ],
      "metadata": {
        "id": "LmLGr0zKx6Be"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}